import streamlit as st
import google.generativeai as genai
from PIL import Image
import edge_tts
import asyncio
import os
import PyPDF2
from duckduckgo_search import DDGS
from streamlit_mic_recorder import mic_recorder # OUVIDOS

NOME = "Marius Web Ultimate"

# --- CONFIGURA√á√ÉO SEGURA ---
try:
    MINHA_CHAVE = st.secrets["GEMINI_KEY"]
except:
    st.error("Configure a GEMINI_KEY nos Secrets do Streamlit.")
    st.stop()

genai.configure(api_key=MINHA_CHAVE)
model = genai.GenerativeModel('gemini-2.5-flash')

# --- CONFIGURA√á√ÉO DE VOZ ---
VOZ_ID = "pt-BR-AntonioNeural"
ARQUIVO_AUDIO = "audio_temp.mp3"

async def gerar_audio(texto):
    communicate = edge_tts.Communicate(texto, VOZ_ID)
    await communicate.save(ARQUIVO_AUDIO)

# --- FERRAMENTAS ---
def ler_pdf(uploaded_file):
    try:
        reader = PyPDF2.PdfReader(uploaded_file)
        texto = ""
        for i in range(min(len(reader.pages), 5)): texto += reader.pages[i].extract_text()
        return texto
    except: return "Erro ao ler PDF."

def pesquisar_web(termo):
    res = ""
    with DDGS() as ddgs:
        for r in ddgs.text(termo, max_results=3): res += f"- {r['title']}: {r['body']}\n"
    return res

# --- INTERFACE ---
st.set_page_config(page_title=NOME, page_icon="üåê", layout="wide")
st.title(f"üåê {NOME}")
st.caption("Voz Neural ‚Ä¢ Vis√£o ‚Ä¢ PDF ‚Ä¢ Web Search ‚Ä¢ Microfone")

if "messages" not in st.session_state:
    st.session_state["messages"] = [{"role": "model", "content": "Sistemas online. Pode falar comigo!"}]

# --- BARRA LATERAL (INPUTS) ---
with st.sidebar:
    st.header("üß∞ Ferramentas")
    
    # 1. Microfone (NOVO!)
    st.subheader("üé§ Falar com Marius")
    audio_gravado = mic_recorder(start_prompt="Gravar üî¥", stop_prompt="Parar ‚èπÔ∏è", key='recorder')
    
    # 2. Uploads
    st.markdown("---")
    img_file = st.file_uploader("üì∏ Analisar Imagem", type=["jpg", "png", "jpeg"])
    pdf_file = st.file_uploader("üìÑ Ler PDF", type=["pdf"])

# --- CHAT ---
for msg in st.session_state.messages:
    avatar = "üë§" if msg["role"] == "user" else "ü§ñ"
    with st.chat_message(msg["role"], avatar=avatar):
        st.write(msg["content"])
        if "audio_bytes" in msg:
            st.audio(msg["audio_bytes"], format="audio/mp3")

# Input de Texto
prompt_texto = st.chat_input("Digite sua mensagem...")

# --- L√ìGICA CENTRAL (PROCESSADOR) ---
input_final = None
tipo_input = "texto" # texto, audio_input

if audio_gravado:
    input_final = audio_gravado['bytes'] # Pega os bytes do √°udio
    tipo_input = "audio_input"
elif prompt_texto:
    input_final = prompt_texto
    tipo_input = "texto"

if input_final:
    # Mostra input do usu√°rio
    if tipo_input == "texto":
        st.session_state.messages.append({"role": "user", "content": input_final})
        st.chat_message("user", avatar="üë§").write(input_final)
    else:
        st.session_state.messages.append({"role": "user", "content": "üé§ [√Åudio enviado]"})
        st.chat_message("user", avatar="üë§").audio(input_final)

    # --- PROCESSAMENTO IA ---
    try:
        contexto_extra = ""
        prompt_ia = "Responda a isso." # Prompt base se for √°udio

        # Se for texto, verifica busca web
        if tipo_input == "texto":
            prompt_ia = input_final
            if any(x in input_final.lower() for x in ["pesquise", "not√≠cia", "pre√ßo", "quem √©"]):
                with st.status("üîç Pesquisando na web..."):
                    web_data = pesquisar_web(input_final)
                    contexto_extra += f"\n[DADOS WEB]:\n{web_data}\n"

        # Se tiver PDF
        if pdf_file:
            conteudo_pdf = ler_pdf(pdf_file)
            contexto_extra += f"\n[PDF CONTEXTO]:\n{conteudo_pdf}\n"

        # GERA√á√ÉO DA RESPOSTA
        response = None
        
        # Cen√°rio A: Tem Imagem
        if img_file:
            img = Image.open(img_file)
            instrucao = contexto_extra + (prompt_ia if tipo_input == "texto" else "Analise a imagem e o √°udio.")
            response = model.generate_content([instrucao, img])
            st.sidebar.image(img, caption="Imagem Analisada")
            
        # Cen√°rio B: Tem √Åudio de Entrada (Microfone)
        elif tipo_input == "audio_input":
            # O Gemini Flash ouve o √°udio diretamente!
            response = model.generate_content([
                contexto_extra + "Ou√ßa este √°udio e responda em portugu√™s.",
                {"mime_type": "audio/wav", "data": input_final}
            ])
            
        # Cen√°rio C: S√≥ Texto
        else:
            response = model.generate_content(contexto_extra + prompt_ia)

        texto_resp = response.text
        
        # Gera Voz de Resposta (Marius fala)
        asyncio.run(gerar_audio(texto_resp))
        with open(ARQUIVO_AUDIO, "rb") as f:
            audio_data = f.read()

        # Mostra resposta
        with st.chat_message("model", avatar="ü§ñ"):
            st.write(texto_resp)
            st.audio(audio_data, format="audio/mp3", autoplay=True)

        st.session_state.messages.append({
            "role": "model", 
            "content": texto_resp,
            "audio_bytes": audio_data
        })

    except Exception as e:
        st.error(f"Erro: {e}")
