import streamlit as st
import google.generativeai as genai
from PIL import Image
import PyPDF2
from duckduckgo_search import DDGS

# --- CONFIGURA√á√ïES VISUAIS (GEMINI STYLE) ---
st.set_page_config(page_title="Marius Gemini", page_icon="‚ú®", layout="wide")

st.markdown("""
<style>
    .stApp { background-color: #0E1117; }
    .stChatMessage { border-radius: 20px; border: 1px solid #303030; }
    .stChatInput textarea { border-radius: 20px; border: 1px solid #444; }
</style>
""", unsafe_allow_html=True)

NOME = "Marius"

# --- SEGURAN√áA ---
try:
    MINHA_CHAVE = st.secrets["GEMINI_KEY"]
except:
    st.error("Configure a GEMINI_KEY nos Secrets.")
    st.stop()

genai.configure(api_key=MINHA_CHAVE)
model = genai.GenerativeModel('gemini-2.5-flash')

# --- FUN√á√ÉO CORRETORA (FIX DO JSON) ---
def stream_parser(response):
    """
    Filtra a resposta bruta do Google para pegar apenas o texto.
    Isso evita que apare√ßa aquele JSON gigante na tela.
    """
    for chunk in response:
        try:
            if chunk.text:
                yield chunk.text
        except:
            pass

# --- FERRAMENTAS ---
def ler_pdf(uploaded_file):
    try:
        reader = PyPDF2.PdfReader(uploaded_file)
        texto = ""
        for i in range(min(len(reader.pages), 10)):
            texto += reader.pages[i].extract_text() + "\n"
        return texto
    except: return ""

def pesquisar_web(termo):
    res = ""
    try:
        with DDGS() as ddgs:
            for r in ddgs.text(termo, max_results=3):
                res += f"- {r['title']}: {r['body']}\n"
    except: pass
    return res

# --- INTERFACE ---
st.title(f"‚ú® {NOME}")
st.caption("Powered by Gemini 2.5 Flash")

if "messages" not in st.session_state:
    st.session_state["messages"] = [{"role": "assistant", "content": "Ol√°. Estou pronto."}]

# --- BARRA LATERAL ---
with st.sidebar:
    st.header("üìÇ Arquivos")
    img_file = st.file_uploader("üì∏ Imagem", type=["jpg", "png", "jpeg"])
    if img_file: st.image(img_file, use_container_width=True)
    st.markdown("---")
    pdf_file = st.file_uploader("üìÑ PDF", type=["pdf"])
    if pdf_file: st.info("PDF Carregado")

# --- HIST√ìRICO ---
for msg in st.session_state.messages:
    avatar = "üë§" if msg["role"] == "user" else "‚ú®"
    st.chat_message(msg["role"], avatar=avatar).write(msg["content"])

# --- INPUT E L√ìGICA ---
prompt = st.chat_input("Pergunte ao Marius...")

if prompt:
    st.session_state.messages.append({"role": "user", "content": prompt})
    st.chat_message("user", avatar="üë§").write(prompt)

    # Prepara contexto
    contexto = ""
    if any(x in prompt.lower() for x in ["pesquise", "quem √©", "pre√ßo", "not√≠cia"]):
        with st.status("üîç Pesquisando...", expanded=False) as status:
            web_data = pesquisar_web(prompt)
            contexto += f"\n[WEB DATA]: {web_data}\n"
            status.update(label="Pesquisa conclu√≠da!", state="complete")
    
    if pdf_file:
        contexto += f"\n[PDF]: {ler_pdf(pdf_file)}\n"

    prompt_final = contexto + prompt

    # --- RESPOSTA STREAMING CORRIGIDA ---
    with st.chat_message("assistant", avatar="‚ú®"):
        try:
            # Pede pro Google mandar stream
            if img_file:
                img = Image.open(img_file)
                response = model.generate_content([prompt_final, img], stream=True)
            else:
                response = model.generate_content(prompt_final, stream=True)
            
            # AQUI EST√Å A CORRE√á√ÉO:
            # Passamos a resposta pela fun√ß√£o 'stream_parser' antes de exibir
            full_response = st.write_stream(stream_parser(response))
            
            st.session_state.messages.append({"role": "assistant", "content": full_response})
            
        except Exception as e:
            st.error(f"Erro: {e}")
